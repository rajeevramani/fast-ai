# Lesson 2

## Questions

* Can we always use a random sample for a validation set? Why or why not?
* What is overfitting? Provide an example.
  * If you train your data for too long, with not enough data and possibly with too many parameters the performance of the model may degragde.
  
* What is a metric? How does it differ from "loss"?
* How can pretrained models help?
* What is the "head" of a model?
* What kinds of features do the early layers of a CNN find? How about the later layers?
* Are image models only useful for photos?
* What is an "architecture"?
* What is segmentation?
* What is y_range used for? When do we need it?
* What are "hyperparameters"?
* What's the best way to avoid failures when using AI in an organization?
* What is a p value?
* What is a prior?
* Provide an example of where the bear classification model might work poorly in production, due to structural or style differences in the training data.
* Where do text models currently have a major deficiency?
* What are possible negative societal implications of text generation models?
* In situations where a model might make mistakes, and those mistakes could be harmful, what is a good alternative to automating a process?
* What kind of tabular data is deep learning particularly good at?
* What's a key downside of directly using a deep learning model for recommendation systems?
* What are the steps of the Drivetrain Approach?
* How do the steps of the Drivetrain Approach map to a recommendation system?
* Create an image recognition model using data you curate, and deploy it on the web.
* What is DataLoaders?
* What four things do we need to tell fastai to create DataLoaders?
* What does the splitter parameter to DataBlock do?
* How do we ensure a random split always gives the same validation set?